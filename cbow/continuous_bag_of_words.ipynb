{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMk38ernvpR8IMMPQ9TyJvt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Basic CBOW implementation"],"metadata":{"id":"Fy2KDJlZCtB9"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"UnMW2rNOCjDs","executionInfo":{"status":"ok","timestamp":1670390730012,"user_tz":-330,"elapsed":5231,"user":{"displayName":"Samuel Davis","userId":"11210077990113460538"}}},"outputs":[],"source":["import torch \n","import torch.nn as nn\n","import torch.optim as optim\n","import spacy"]},{"cell_type":"code","source":["class CBOW(nn.Module):\n","  def __init__(self, embedding_size=100, vocab_size=-1):\n","    super().__init__()\n","    self.embeddings = nn.Embedding(vocab_size, embedding_size)\n","    self.linear = nn.Linear(embedding_size, vocab_size)\n","\n","  def forward(self, imputs):\n","    # inputs: batch_size * context * 2 (context = 2)\n","    embeddings = self.embeddings(input) # batch * 4 * 100\n","    embeddings = embeddings.mean(1) # batch * 1 * 100\n","    embeddings = embeddings.squeeze(1) # batch * 100\n","    \n","    return self.linear(embeddings)\n","  \n"],"metadata":{"id":"vTO0mn1KC612"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"tdwavgW-FCxO","executionInfo":{"status":"ok","timestamp":1670403951118,"user_tz":-330,"elapsed":655,"user":{"displayName":"Samuel Davis","userId":"11210077990113460538"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"PyD7a-X1FGAU","executionInfo":{"status":"ok","timestamp":1670403951120,"user_tz":-330,"elapsed":8,"user":{"displayName":"Samuel Davis","userId":"11210077990113460538"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QncreXgbFIM2"},"execution_count":null,"outputs":[]}]}