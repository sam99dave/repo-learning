{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1UxiIMGHRQikMckiNq2vNW0w5BzwV_dp7","authorship_tag":"ABX9TyNW3rvxd0lbY6iYGkmxeo51"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Generator & Discriminator"],"metadata":{"id":"lKjJB7qPA_Ff"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"kScMArpum-Fn","executionInfo":{"status":"ok","timestamp":1671733984831,"user_tz":-330,"elapsed":3550,"user":{"displayName":"Samuel Davis","userId":"11210077990113460538"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class Block(nn.Module):\n","  def __init__(self, in_channels, out_channels, stride):\n","    super(Block, self).__init__()\n","    self.conv = nn.Sequential(\n","        nn.Conv2d(\n","            in_channels,\n","            out_channels,\n","            4,\n","            stride,\n","            1,\n","            bias=False,\n","            padding_mode='reflect'\n","        ),\n","        nn.InstanceNorm2d(out_channels),\n","        nn.LeakyReLU(0.2),\n","    )\n","\n","  def forward(self, x):\n","    return self.conv(x)\n","\n","class Discriminator(nn.Module):\n","  def __init__(self, in_channels, features=[64, 128, 256, 512]):\n","    super().__init__()\n","    self.initial = nn.Sequential(\n","        nn.Conv2d(\n","            in_channels,\n","            features[0],\n","            kernel_size=4,\n","            stride=2,\n","            padding=1,\n","            padding_mode='reflect'\n","        ),\n","        nn.LeakyReLU(0.2),\n","    )\n","\n","    layers = []\n","    in_channels = features[0]\n","    for feature in features[1:]:\n","      layers.append(\n","          Block(\n","              in_channels,\n","              feature,\n","              stride=1 if feature==features[-1] else 2,\n","          )\n","      )\n","\n","      in_channels = feature\n","    \n","    layers.append(\n","        nn.Conv2d(\n","            in_channels,\n","            1,\n","            kernel_size=4,\n","            stride=1,\n","            padding=1,\n","            padding_mode='reflect'\n","        )\n","    )\n","\n","    self.model = nn.Sequential(*layers)\n","\n","  def forward(self, x):\n","    x = self.initial(x)\n","    return torch.sigmoid(self.model(x))\n","\n","# def test():\n","#   x = torch.randn((1, 3, 256, 256))\n","#   model = Discriminator(in_channels=3)\n","#   preds = model(x)\n","#   print(model)\n","#   print(preds.shape)\n","#   # shape: (1, 1, 30, 30), each value in the 30x30 grid maps a patch of \n","#   # 70x70 in the original image\n","# test()\n","\n","class ConvBlock(nn.Module):\n","  def __init__(self, in_channels, out_channels, down=True, use_act=True, **kwargs):\n","    super().__init__()\n","    self.conv = nn.Sequential(\n","        nn.Conv2d(in_channels, out_channels, padding_mode='reflect', **kwargs)\n","        if down\n","        else nn.ConvTranspose2d(in_channels, out_channels, **kwargs),\n","        nn.InstanceNorm2d(out_channels),\n","        nn.ReLU(inplace=True) if use_act else nn.Identity()\n","    )\n","  \n","  def forward(self, x):\n","    return self.conv(x)\n","\n","class ResidualBlock(nn.Module):\n","  def __init__(self, channels):\n","    super().__init__()\n","    self.block = nn.Sequential(\n","        ConvBlock(channels, channels, kernel_size=3, padding=1),\n","        ConvBlock(channels, channels, use_act=False, kernel_size=3, padding=1),\n","    )\n","  \n","  def forward(self, x):\n","    return x + self.block(x)\n","\n","class Generator(nn.Module):\n","  def __init__(self, img_channels, num_features=64, num_residuals=9):\n","    super().__init__()\n","    self.initial = nn.Sequential(\n","        nn.Conv2d(img_channels, num_features, kernel_size=7, stride=1, padding=3, padding_mode='reflect'),\n","        nn.ReLU(inplace=True),\n","    )\n","\n","    self.down_blocks = nn.ModuleList(\n","        [\n","          ConvBlock(num_features, num_features*2, kernel_size=3, stride=2, padding=1),\n","          ConvBlock(num_features*2, num_features*4, kernel_size=3, stride=2, padding=1),\n","        ]\n","    )\n","\n","    self.residual_blocks = nn.Sequential(\n","        *[ResidualBlock(num_features*4) for _ in range(num_residuals)]\n","    )\n","\n","    self.up_blocks = nn.ModuleList(\n","        [\n","          ConvBlock(num_features*4, num_features*2, down=False, kernel_size=3, stride=2, padding=1, output_padding=1),\n","          ConvBlock(num_features*2, num_features, down=False, kernel_size=3, stride=2, padding=1, output_padding=1)\n","        ]\n","    )\n","\n","    self.last = nn.Conv2d(num_features, img_channels, kernel_size=7, stride=1, padding=3, padding_mode='reflect')\n","  \n","  def forward(self, x):\n","    x = self.initial(x)\n","    for layer in self.down_blocks:\n","      x = layer(x)\n","    x = self.residual_blocks(x)\n","    for layer in self.up_blocks:\n","      x = layer(x)\n","    return torch.tanh(self.last(x))\n","\n","# def test():\n","#   img_channels = 3\n","#   img_size = 256\n","#   x = torch.randn((2, 3, img_size, img_size))\n","#   model = Generator(img_channels)\n","#   preds = model(x)\n","#   print(model)\n","#   print(preds.shape)\n","# test()"]},{"cell_type":"markdown","source":["## Config"],"metadata":{"id":"cw5jgb8tcKV8"}},{"cell_type":"code","source":["import torch\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","TRAIN_DIR = \"horse2zebra/train\"\n","VAL_DIR = \"horse2zebra/val\"\n","ASSET_PATH = '/content/drive/MyDrive/Tutorials/aladdin_persson_gans/cycle_gans_results'\n","BATCH_SIZE = 1\n","LEARNING_RATE = 1e-5\n","LAMBDA_IDENTITY = 0.0\n","LAMBDA_CYCLE = 10\n","NUM_WORKERS = 4\n","NUM_EPOCHS = 10\n","LOAD_MODEL = False\n","SAVE_MODEL = True\n","CHECKPOINT_GEN_H = f\"{ASSET_PATH}/genh.pth.tar\"\n","CHECKPOINT_GEN_Z = f\"{ASSET_PATH}/genz.pth.tar\"\n","CHECKPOINT_CRITIC_H = f\"{ASSET_PATH}/critich.pth.tar\"\n","CHECKPOINT_CRITIC_Z = f\"{ASSET_PATH}/criticz.pth.tar\"\n","\n","transforms = A.Compose(\n","    [\n","        A.Resize(width=256, height=256),\n","        A.HorizontalFlip(p=0.5),\n","        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255),\n","        ToTensorV2(),\n","    ],\n","    additional_targets={\"image0\": \"image\"},\n",")"],"metadata":{"id":"8q7k0DEccKlb","executionInfo":{"status":"ok","timestamp":1671733990795,"user_tz":-330,"elapsed":3156,"user":{"displayName":"Samuel Davis","userId":"11210077990113460538"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## Utils"],"metadata":{"id":"RKPOfRUTcS5Z"}},{"cell_type":"code","source":["import random, torch, os, numpy as np\n","import torch.nn as nn\n","import copy\n","\n","def save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n","    print(\"=> Saving checkpoint\")\n","    checkpoint = {\n","        \"state_dict\": model.state_dict(),\n","        \"optimizer\": optimizer.state_dict(),\n","    }\n","    torch.save(checkpoint, filename)\n","\n","\n","def load_checkpoint(checkpoint_file, model, optimizer, lr):\n","    print(\"=> Loading checkpoint\")\n","    checkpoint = torch.load(checkpoint_file, map_location=DEVICE)\n","    model.load_state_dict(checkpoint[\"state_dict\"])\n","    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n","\n","    # If we don't do this then it will just have learning rate of old checkpoint\n","    # and it will lead to many hours of debugging \\:\n","    for param_group in optimizer.param_groups:\n","        param_group[\"lr\"] = lr\n","\n","\n","def seed_everything(seed=42):\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False"],"metadata":{"id":"4IUuH9prcTG_","executionInfo":{"status":"ok","timestamp":1671733992442,"user_tz":-330,"elapsed":3,"user":{"displayName":"Samuel Davis","userId":"11210077990113460538"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Dataset"],"metadata":{"id":"XRwmEuniaoe0"}},{"cell_type":"code","source":["# !pip install -q kaggle\n","# !mkdir ~/.kaggle\n","# !cp /content/kaggle.json ~/.kaggle\n","# !chmod 600 ~/.kaggle/kaggle.json\n","# !kaggle datasets download -d suyashdamle/cyclegan\n","# !unzip /content/cyclegan.zip"],"metadata":{"id":"cilqKG3Va2KP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import Dataset\n","import os\n","from PIL import Image\n","import numpy as np"],"metadata":{"id":"VhZ8zQjbO_5e","executionInfo":{"status":"ok","timestamp":1671733996014,"user_tz":-330,"elapsed":4,"user":{"displayName":"Samuel Davis","userId":"11210077990113460538"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["class HorseZebraDataset(Dataset):\n","  def __init__(self, root_zebra, root_horse, transform=None):\n","    super().__init__()\n","    self.root_horse = root_horse\n","    self.root_zebra = root_zebra\n","    self.transform = transform\n","\n","    self.zebra_images = os.listdir(self.root_zebra)\n","    self.horse_images = os.listdir(self.root_horse)\n","    self.length_dataset = max(len(self.zebra_images), len(self.horse_images)) # 1000, 1500 (example)\n","    self.zebra_len = len(self.zebra_images)\n","    self.horse_len = len(self.horse_images)\n","\n","  def __len__(self):\n","    return self.length_dataset\n","  \n","  def __getitem__(self, index):\n","    zebra_img = self.zebra_images[index % self.zebra_len]\n","    horse_img = self.horse_images[index % self.horse_len]\n","\n","    zebra_path = os.path.join(self.root_zebra, zebra_img)\n","    horse_path = os.path.join(self.root_horse, horse_img)\n","\n","    zebra_img = np.array(Image.open(zebra_path).convert('RGB'))\n","    horse_img = np.array(Image.open(horse_path).convert('RGB'))\n","\n","    if self.transform:\n","      augmentations = self.transform(image=zebra_img, image0=horse_img)\n","      zebra_img = augmentations['image']\n","      horse_img = augmentations['image0']\n","\n","    return zebra_img, horse_img"],"metadata":{"id":"QCGeu15qckdl","executionInfo":{"status":"ok","timestamp":1671734178244,"user_tz":-330,"elapsed":4,"user":{"displayName":"Samuel Davis","userId":"11210077990113460538"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["## Training"],"metadata":{"id":"LV-aCVysflJH"}},{"cell_type":"code","source":["import torch\n","import sys\n","from torch.utils.data import DataLoader\n","import torch.nn as nn\n","import torch.optim as optim\n","from tqdm import tqdm\n","from torchvision.utils import save_image"],"metadata":{"id":"G7kSmqSNU8ry","executionInfo":{"status":"ok","timestamp":1671734007620,"user_tz":-330,"elapsed":3,"user":{"displayName":"Samuel Davis","userId":"11210077990113460538"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def train_fn(\n","    disc_H, disc_Z, gen_Z, gen_H, loader, opt_disc, opt_gen, l1, mse, d_scaler, g_scaler\n","):\n","    H_reals = 0\n","    H_fakes = 0\n","    loop = tqdm(loader, leave=True)\n","\n","    for idx, (zebra, horse) in enumerate(loop):\n","        zebra = zebra.to(DEVICE)\n","        horse = horse.to(DEVICE)\n","\n","        # Train Discriminators H and Z\n","        with torch.cuda.amp.autocast():\n","            fake_horse = gen_H(zebra)\n","            D_H_real = disc_H(horse)\n","            D_H_fake = disc_H(fake_horse.detach())\n","            H_reals += D_H_real.mean().item()\n","            H_fakes += D_H_fake.mean().item()\n","            D_H_real_loss = mse(D_H_real, torch.ones_like(D_H_real))\n","            D_H_fake_loss = mse(D_H_fake, torch.zeros_like(D_H_fake))\n","            D_H_loss = D_H_real_loss + D_H_fake_loss\n","\n","            fake_zebra = gen_Z(horse)\n","            D_Z_real = disc_Z(zebra)\n","            D_Z_fake = disc_Z(fake_zebra.detach())\n","            D_Z_real_loss = mse(D_Z_real, torch.ones_like(D_Z_real))\n","            D_Z_fake_loss = mse(D_Z_fake, torch.zeros_like(D_Z_fake))\n","            D_Z_loss = D_Z_real_loss + D_Z_fake_loss\n","\n","            # put it togethor\n","            D_loss = (D_H_loss + D_Z_loss) / 2\n","\n","        opt_disc.zero_grad()\n","        d_scaler.scale(D_loss).backward()\n","        d_scaler.step(opt_disc)\n","        d_scaler.update()\n","\n","        # Train Generators H and Z\n","        with torch.cuda.amp.autocast():\n","            # adversarial loss for both generators\n","            D_H_fake = disc_H(fake_horse)\n","            D_Z_fake = disc_Z(fake_zebra)\n","            loss_G_H = mse(D_H_fake, torch.ones_like(D_H_fake))\n","            loss_G_Z = mse(D_Z_fake, torch.ones_like(D_Z_fake))\n","\n","            # cycle loss\n","            cycle_zebra = gen_Z(fake_horse)\n","            cycle_horse = gen_H(fake_zebra)\n","            cycle_zebra_loss = l1(zebra, cycle_zebra)\n","            cycle_horse_loss = l1(horse, cycle_horse)\n","\n","            # identity loss (remove these for efficiency if you set lambda_identity=0)\n","            identity_zebra = gen_Z(zebra)\n","            identity_horse = gen_H(horse)\n","            identity_zebra_loss = l1(zebra, identity_zebra)\n","            identity_horse_loss = l1(horse, identity_horse)\n","\n","            # add all togethor\n","            G_loss = (\n","                loss_G_Z\n","                + loss_G_H\n","                + cycle_zebra_loss * LAMBDA_CYCLE\n","                + cycle_horse_loss * LAMBDA_CYCLE\n","                + identity_horse_loss * LAMBDA_IDENTITY\n","                + identity_zebra_loss * LAMBDA_IDENTITY\n","            )\n","\n","        opt_gen.zero_grad()\n","        g_scaler.scale(G_loss).backward()\n","        g_scaler.step(opt_gen)\n","        g_scaler.update()\n","\n","        if idx % 50 == 0:\n","            save_image(fake_horse * 0.5 + 0.5, f\"{ASSET_PATH}/saved_images/horse_{idx}.png\")\n","            save_image(fake_zebra * 0.5 + 0.5, f\"{ASSET_PATH}/saved_images/zebra_{idx}.png\")\n","\n","        loop.set_postfix(H_real=H_reals / (idx + 1), H_fake=H_fakes / (idx + 1))\n","\n","def main():\n","    disc_H = Discriminator(in_channels=3).to(DEVICE)\n","    disc_Z = Discriminator(in_channels=3).to(DEVICE)\n","    gen_Z = Generator(img_channels=3, num_residuals=9).to(DEVICE)\n","    gen_H = Generator(img_channels=3, num_residuals=9).to(DEVICE)\n","    opt_disc = optim.Adam(\n","        list(disc_H.parameters()) + list(disc_Z.parameters()),\n","        lr=LEARNING_RATE,\n","        betas=(0.5, 0.999),\n","    )\n","\n","    opt_gen = optim.Adam(\n","        list(gen_Z.parameters()) + list(gen_H.parameters()),\n","        lr=LEARNING_RATE,\n","        betas=(0.5, 0.999),\n","    )\n","\n","    L1 = nn.L1Loss()\n","    mse = nn.MSELoss()\n","\n","    if LOAD_MODEL:\n","        load_checkpoint(\n","            CHECKPOINT_GEN_H,\n","            gen_H,\n","            opt_gen,\n","            LEARNING_RATE,\n","        )\n","        load_checkpoint(\n","            CHECKPOINT_GEN_Z,\n","            gen_Z,\n","            opt_gen,\n","            LEARNING_RATE,\n","        )\n","        load_checkpoint(\n","            CHECKPOINT_CRITIC_H,\n","            disc_H,\n","            opt_disc,\n","            LEARNING_RATE,\n","        )\n","        load_checkpoint(\n","            CHECKPOINT_CRITIC_Z,\n","            disc_Z,\n","            opt_disc,\n","            LEARNING_RATE,\n","        )\n","\n","    dataset = HorseZebraDataset(\n","        root_horse=TRAIN_DIR + \"/horses\",\n","        root_zebra=TRAIN_DIR + \"/zebras\",\n","        transform=transforms,\n","    )\n","    val_dataset = HorseZebraDataset(\n","        root_horse=VAL_DIR + \"/horses\",\n","        root_zebra=VAL_DIR + \"/zebras\",\n","        transform=transforms,\n","    )\n","    val_loader = DataLoader(\n","        val_dataset,\n","        batch_size=1,\n","        shuffle=False,\n","        pin_memory=True,\n","    )\n","    loader = DataLoader(\n","        dataset,\n","        batch_size=BATCH_SIZE,\n","        shuffle=True,\n","        num_workers=NUM_WORKERS,\n","        pin_memory=True,\n","    )\n","    g_scaler = torch.cuda.amp.GradScaler()\n","    d_scaler = torch.cuda.amp.GradScaler()\n","\n","    for epoch in range(NUM_EPOCHS):\n","        train_fn(\n","            disc_H,\n","            disc_Z,\n","            gen_Z,\n","            gen_H,\n","            loader,\n","            opt_disc,\n","            opt_gen,\n","            L1,\n","            mse,\n","            d_scaler,\n","            g_scaler,\n","        )\n","\n","        if SAVE_MODEL:\n","            save_checkpoint(gen_H, opt_gen, filename=CHECKPOINT_GEN_H)\n","            save_checkpoint(gen_Z, opt_gen, filename=CHECKPOINT_GEN_Z)\n","            save_checkpoint(disc_H, opt_disc, filename=CHECKPOINT_CRITIC_H)\n","            save_checkpoint(disc_Z, opt_disc, filename=CHECKPOINT_CRITIC_Z)\n","\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"7DhEqruPgNwf","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1671736695546,"user_tz":-330,"elapsed":2514436,"user":{"displayName":"Samuel Davis","userId":"11210077990113460538"}},"outputId":"6f1cd089-d039-4ac2-f095-4fe8a05ff93a"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 1334/1334 [05:16<00:00,  4.21it/s, H_fake=0.445, H_real=0.552]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","=> Saving checkpoint\n","=> Saving checkpoint\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1334/1334 [05:08<00:00,  4.32it/s, H_fake=0.435, H_real=0.559]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","=> Saving checkpoint\n","=> Saving checkpoint\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1334/1334 [05:07<00:00,  4.34it/s, H_fake=0.432, H_real=0.563]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","=> Saving checkpoint\n","=> Saving checkpoint\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1334/1334 [05:07<00:00,  4.34it/s, H_fake=0.426, H_real=0.568]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","=> Saving checkpoint\n","=> Saving checkpoint\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1334/1334 [05:08<00:00,  4.32it/s, H_fake=0.423, H_real=0.573]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","=> Saving checkpoint\n","=> Saving checkpoint\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1334/1334 [05:07<00:00,  4.34it/s, H_fake=0.42, H_real=0.575]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","=> Saving checkpoint\n","=> Saving checkpoint\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1334/1334 [05:07<00:00,  4.34it/s, H_fake=0.417, H_real=0.578]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","=> Saving checkpoint\n","=> Saving checkpoint\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1334/1334 [05:06<00:00,  4.35it/s, H_fake=0.412, H_real=0.582]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","=> Saving checkpoint\n","=> Saving checkpoint\n"]},{"output_type":"stream","name":"stderr","text":["  8%|▊         | 101/1334 [00:24<04:59,  4.12it/s, H_fake=0.407, H_real=0.594]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-3b1b1215e6ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-15-3b1b1215e6ff>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         train_fn(\n\u001b[0m\u001b[1;32m    153\u001b[0m             \u001b[0mdisc_H\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mdisc_Z\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-3b1b1215e6ff>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(disc_H, disc_Z, gen_Z, gen_H, loader, opt_disc, opt_gen, l1, mse, d_scaler, g_scaler)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mopt_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mg_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mg_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mg_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":[],"metadata":{"id":"6Mx4DA1OHJMA"},"execution_count":null,"outputs":[]}]}