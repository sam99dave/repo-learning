{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["F9lHrHSDoimP","yGdWUD5Zolsm","KwaA309orDKg","JO5uGrw8osN_","f7rsXs-ppARH","5-hqYHDLpWaS","iOvJsEYqoGJb"],"authorship_tag":"ABX9TyP+Ie/cv6/Es804j6bFboUE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Others"],"metadata":{"id":"F9lHrHSDoimP"}},{"cell_type":"markdown","source":["## Config"],"metadata":{"id":"yGdWUD5Zolsm"}},{"cell_type":"code","source":["import torch\n","from PIL import Image\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","LOAD_MODEL = True\n","SAVE_MODEL = True\n","CHECKPOINT_GEN = \"gen.pth.tar\"\n","CHECKPOINT_DISC = \"disc.pth.tar\"\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","LEARNING_RATE = 1e-4\n","NUM_EPOCHS = 100\n","BATCH_SIZE = 16\n","NUM_WORKERS = 4\n","HIGH_RES = 96\n","LOW_RES = HIGH_RES // 4\n","IMG_CHANNELS = 3\n","\n","highres_transform = A.Compose(\n","    [\n","        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n","        ToTensorV2(),\n","    ]\n",")\n","\n","lowres_transform = A.Compose(\n","    [\n","        A.Resize(width=LOW_RES, height=LOW_RES, interpolation=Image.BICUBIC),\n","        A.Normalize(mean=[0, 0, 0], std=[1, 1, 1]),\n","        ToTensorV2(),\n","    ]\n",")\n","\n","both_transforms = A.Compose(\n","    [\n","        A.RandomCrop(width=HIGH_RES, height=HIGH_RES),\n","        A.HorizontalFlip(p=0.5),\n","        A.RandomRotate90(p=0.5),\n","    ]\n",")\n","\n","test_transform = A.Compose(\n","    [\n","        A.Normalize(mean=[0, 0, 0], std=[1, 1, 1]),\n","        ToTensorV2(),\n","    ]\n",")"],"metadata":{"id":"22x9TwFpok_E","executionInfo":{"status":"ok","timestamp":1673454074548,"user_tz":-330,"elapsed":2378,"user":{"displayName":"Samuel Davis","userId":"11210077990113460538"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["## Loss"],"metadata":{"id":"KwaA309orDKg"}},{"cell_type":"code","source":["import torch.nn as nn\n","from torchvision.models import vgg19\n","\n","# phi_5, 4 5th conv layer before maxpooling but after activation\n","\n","class VGGLoss(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.vgg = vgg19(pretrained=True).features[:36].eval().to(DEVICE)\n","    self.loss = nn.MSELoss()\n","\n","    for param in self.vgg.parameters():\n","      param.requires_grad = False\n","  \n","  def forward(self, input, target):\n","    vgg_input_features = self.vgg(input)\n","    vgg_target_features = self.vgg(target)\n","    return self.loss(vgg_input_features, vgg_target_features)"],"metadata":{"id":"GJ6k2HsHrEHn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Dataset"],"metadata":{"id":"JO5uGrw8osN_"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","from torch.utils.data import Dataset, DataLoader\n","from PIL import Image\n","\n","\n","class MyImageFolder(Dataset):\n","    def __init__(self, root_dir):\n","        super(MyImageFolder, self).__init__()\n","        self.data = []\n","        self.root_dir = root_dir\n","        self.class_names = os.listdir(root_dir)\n","\n","        for index, name in enumerate(self.class_names):\n","            files = os.listdir(os.path.join(root_dir, name))\n","            self.data += list(zip(files, [index] * len(files)))\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        img_file, label = self.data[index]\n","        root_and_dir = os.path.join(self.root_dir, self.class_names[label])\n","\n","        image = np.array(Image.open(os.path.join(root_and_dir, img_file)))\n","        image = both_transforms(image=image)[\"image\"]\n","        high_res = highres_transform(image=image)[\"image\"]\n","        low_res = lowres_transform(image=image)[\"image\"]\n","        return low_res, high_res\n","\n","\n","def test():\n","    dataset = MyImageFolder(root_dir=\"new_data/\")\n","    loader = DataLoader(dataset, batch_size=1, num_workers=8)\n","\n","    for low_res, high_res in loader:\n","        print(low_res.shape)\n","        print(high_res.shape)\n","\n","\n","if __name__ == \"__main__\":\n","    test()"],"metadata":{"id":"M7anzEDyolKv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Utils"],"metadata":{"id":"f7rsXs-ppARH"}},{"cell_type":"code","source":["import torch\n","import os\n","import numpy as np\n","from PIL import Image\n","from torchvision.utils import save_image\n","\n","\n","def gradient_penalty(critic, real, fake, device):\n","    BATCH_SIZE, C, H, W = real.shape\n","    alpha = torch.rand((BATCH_SIZE, 1, 1, 1)).repeat(1, C, H, W).to(device)\n","    interpolated_images = real * alpha + fake.detach() * (1 - alpha)\n","    interpolated_images.requires_grad_(True)\n","\n","    # Calculate critic scores\n","    mixed_scores = critic(interpolated_images)\n","\n","    # Take the gradient of the scores with respect to the images\n","    gradient = torch.autograd.grad(\n","        inputs=interpolated_images,\n","        outputs=mixed_scores,\n","        grad_outputs=torch.ones_like(mixed_scores),\n","        create_graph=True,\n","        retain_graph=True,\n","    )[0]\n","    gradient = gradient.view(gradient.shape[0], -1)\n","    gradient_norm = gradient.norm(2, dim=1)\n","    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n","    return gradient_penalty\n","\n","\n","def save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n","    print(\"=> Saving checkpoint\")\n","    checkpoint = {\n","        \"state_dict\": model.state_dict(),\n","        \"optimizer\": optimizer.state_dict(),\n","    }\n","    torch.save(checkpoint, filename)\n","\n","\n","def load_checkpoint(checkpoint_file, model, optimizer, lr):\n","    print(\"=> Loading checkpoint\")\n","    checkpoint = torch.load(checkpoint_file, map_location=DEVICE)\n","    model.load_state_dict(checkpoint[\"state_dict\"])\n","    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n","\n","    # If we don't do this then it will just have learning rate of old checkpoint\n","    # and it will lead to many hours of debugging \\:\n","    for param_group in optimizer.param_groups:\n","        param_group[\"lr\"] = lr\n","\n","\n","def plot_examples(low_res_folder, gen):\n","    files = os.listdir(low_res_folder)\n","\n","    gen.eval()\n","    for file in files:\n","        image = Image.open(\"test_images/\" + file)\n","        with torch.no_grad():\n","            upscaled_img = gen(\n","                test_transform(image=np.asarray(image))[\"image\"]\n","                .unsqueeze(0)\n","                .to(DEVICE)\n","            )\n","        save_image(upscaled_img * 0.5 + 0.5, f\"saved/{file}\")\n","    gen.train()"],"metadata":{"id":"YgpzGmr1pUM5","executionInfo":{"status":"ok","timestamp":1673454249477,"user_tz":-330,"elapsed":3,"user":{"displayName":"Samuel Davis","userId":"11210077990113460538"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## Train"],"metadata":{"id":"5-hqYHDLpWaS"}},{"cell_type":"code","source":["import torch\n","from torch import nn\n","from torch import optim\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","\n","torch.backends.cudnn.benchmark = True\n","\n","\n","def train_fn(loader, disc, gen, opt_gen, opt_disc, mse, bce, vgg_loss):\n","    loop = tqdm(loader, leave=True)\n","\n","    for idx, (low_res, high_res) in enumerate(loop):\n","        high_res = high_res.to(DEVICE)\n","        low_res = low_res.to(DEVICE)\n","        \n","        ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n","        fake = gen(low_res)\n","        disc_real = disc(high_res)\n","        disc_fake = disc(fake.detach())\n","        disc_loss_real = bce(\n","            disc_real, torch.ones_like(disc_real) - 0.1 * torch.rand_like(disc_real)\n","        )\n","        disc_loss_fake = bce(disc_fake, torch.zeros_like(disc_fake))\n","        loss_disc = disc_loss_fake + disc_loss_real\n","\n","        opt_disc.zero_grad()\n","        loss_disc.backward()\n","        opt_disc.step()\n","\n","        # Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n","        disc_fake = disc(fake)\n","        #l2_loss = mse(fake, high_res)\n","        adversarial_loss = 1e-3 * bce(disc_fake, torch.ones_like(disc_fake))\n","        loss_for_vgg = 0.006 * vgg_loss(fake, high_res)\n","        gen_loss = loss_for_vgg + adversarial_loss\n","\n","        opt_gen.zero_grad()\n","        gen_loss.backward()\n","        opt_gen.step()\n","\n","        if idx % 200 == 0:\n","            plot_examples(\"test_images/\", gen)\n","\n","\n","def main():\n","    dataset = MyImageFolder(root_dir=\"new_data/\")\n","    loader = DataLoader(\n","        dataset,\n","        batch_size=BATCH_SIZE,\n","        shuffle=True,\n","        pin_memory=True,\n","        num_workers=NUM_WORKERS,\n","    )\n","    gen = Generator(in_channels=3).to(DEVICE)\n","    disc = Discriminator(img_channels=3).to(DEVICE)\n","    opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.999))\n","    opt_disc = optim.Adam(disc.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.999))\n","    mse = nn.MSELoss()\n","    bce = nn.BCEWithLogitsLoss()\n","    vgg_loss = VGGLoss()\n","\n","    if LOAD_MODEL:\n","        load_checkpoint(\n","            CHECKPOINT_GEN,\n","            gen,\n","            opt_gen,\n","            LEARNING_RATE,\n","        )\n","        load_checkpoint(\n","           CHECKPOINT_DISC, disc, opt_disc, LEARNING_RATE,\n","        )\n","\n","    for epoch in range(NUM_EPOCHS):\n","        train_fn(loader, disc, gen, opt_gen, opt_disc, mse, bce, vgg_loss)\n","\n","        if SAVE_MODEL:\n","            save_checkpoint(gen, opt_gen, filename=CHECKPOINT_GEN)\n","            save_checkpoint(disc, opt_disc, filename=CHECKPOINT_DISC)\n","\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"W6OAvJ30pbA9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model"],"metadata":{"id":"iOvJsEYqoGJb"}},{"cell_type":"code","source":["import torch\n","from torch import nn\n","\n","class ConvBlock(nn.Module):\n","  def __init__(\n","      self,\n","      in_channels,\n","      out_channels,\n","      discriminator=False,\n","      use_act = True,\n","      use_bn=True,\n","      **kwargs,\n","  ):\n","    super().__init__()\n","    self.use_act = use_act\n","    self.cnn = nn.Conv2d(in_channels, out_channels, **kwargs, bias=not use_bn)\n","    self.bn = nn.BatchNorm2d(out_channels) if use_bn else nn.Identity()\n","    self.act = nn.LeakyReLU(0.2, inplace=True) if discriminator else nn.PReLU(num_parameters=out_channels)\n","  \n","  def forward(self, x):\n","    print(x.shape)\n","    return self.act(self.bn(self.cnn(x))) if self.use_act else self.bn(self.cnn(x))\n","\n","class UpsampleBlock(nn.Module):\n","  def __init__(self, in_channels, scale_factor):\n","    super().__init__()\n","    self.conv = nn.Conv2d(in_channels, in_channels*scale_factor ** 2, 3, 1, 1)\n","    self.ps = nn.PixelShuffle(scale_factor) # in_channels * 4, H, W -> in_c, H*2, W*2\n","    self.act = nn.PReLU(num_parameters=in_channels)\n","  \n","  def forward(self, x):\n","    return self.act(self.ps(self.conv(x)))\n","\n","class ResidualBlock(nn.Module):\n","  def __init__(self, in_channels):\n","    super().__init__()\n","    self.block1 = ConvBlock(in_channels,in_channels,kernel_size=3,stride=1,padding=1)\n","    self.block2 = ConvBlock(in_channels, in_channels,kernel_size=3,stride=1,padding=1,use_act=False)\n","  \n","  def forward(self, x):\n","    out = self.block1(x)\n","    out = self.block2(out)\n","\n","    return out + x\n","\n","class Generator(nn.Module):\n","  def __init__(self, in_channels=3, num_channels=64, num_blocks=16):\n","    super().__init__()\n","    self.initial = ConvBlock(in_channels, num_channels, kernel_size=9, stride=1, padding=4, use_bn=False)\n","    layers = []\n","    for _ in range(num_blocks):\n","      layers.append(\n","          ResidualBlock(num_channels)\n","      )\n","    self.residuals = nn.Sequential(*layers)\n","    self.middle = ConvBlock(num_channels, num_channels, kernel_size=3, stride=1, padding=1, use_act=False)\n","    self.upsampler = nn.Sequential(UpsampleBlock(num_channels, 2), UpsampleBlock(num_channels, 2))\n","    self.final = nn.Conv2d(num_channels, in_channels, kernel_size=9, stride=1, padding=4)\n","\n","\n","  def forward(self, x):\n","    initial = self.initial(x)\n","    x = self.residuals(initial)\n","    x = self.middle(x) + initial\n","    x = self.upsampler(x)\n","    \n","    return torch.tanh(self.final(x))\n","\n","class Discriminator(nn.Module):\n","  def __init__(self, in_channels=3, features=[64, 64, 128, 128, 256, 256, 512, 512]):\n","    super().__init__()\n","    blocks = []\n","    for idx, feature in enumerate(features):\n","      blocks.append(\n","          ConvBlock(\n","              in_channels,\n","              feature,\n","              kernel_size=3,\n","              stride=1+ idx%2,\n","              padding=1,\n","              discriminator=True,\n","              use_act=True,\n","              use_bn=False if idx==0 else True,\n","          )\n","      )\n","      in_channels = feature\n","\n","    self.blocks = nn.Sequential(*blocks)\n","    self.classifier = nn.Sequential(\n","        nn.AdaptiveAvgPool2d((6,6)), # even if the input changes this willbeing it to 6x6\n","        nn.Flatten(),\n","        nn.Linear(512*6*6, 1024),\n","        nn.LeakyReLU(0.2, inplace=True),\n","        nn.Linear(1024, 1),\n","    )\n","\n","  def forward(self, x):\n","    x = self.blocks(x)\n","\n","    return self.classifier(x)\n","\n","# def test():\n","#     low_resolution = 24  # 96x96 -> 24x24\n","#     with torch.cuda.amp.autocast():\n","#         x = torch.randn((5, 3, low_resolution, low_resolution))\n","#         gen = Generator()\n","#         gen_out = gen(x)\n","#         print(f'lol: {gen_out.shape}')\n","#         disc = Discriminator()\n","#         disc_out = disc(gen_out)\n","\n","#         print(gen_out.shape)\n","#         print(disc_out.shape)\n","\n","\n","# if __name__ == \"__main__\":\n","#     test()"],"metadata":{"id":"GMfRM0-sq3ql"},"execution_count":null,"outputs":[]}]}